{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c24f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat.columns:\n",
    "    # cat.replace({\" \":np.nan}, inplace=True)\n",
    "    cat.loc[cat[col] == ' ', col] = 'other'\n",
    "    # cat = cat.fillna(cat.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e369ff85",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(list(num_B_sqrt.RAMNT_24.value_counts()))\n",
    "#Use the get_constant_features functions to get all the constant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8a7766",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categoricals.columns:\n",
    "    if col.startswith('RFA') or col.startswith('MDMAUD'):\n",
    "        categoricals[col] = categoricals[col].str[:2]\n",
    "        #categoricals[col] = categoricals[col].replace({\" \":np.nan}, inplace=True)\n",
    "        #categoricals[col] = categoricals[col].fillna(df.mode().iloc[0])\n",
    "    elif col.startswith('DOMAIN'):\n",
    "        categoricals[col] = categoricals[col].str[:1]\n",
    "        #categoricals.replace({\" \":np.nan}, inplace=True)\n",
    "        #categoricals.fillna(df.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# categoricals.loc[categoricals['GENDER'] == ' ', 'GENDER'] = 'U'\n",
    "# categoricals.loc[categoricals['GENDER'] == 'J', 'GENDER'] = 'U'\n",
    "# categoricals.loc[categoricals['GENDER'] == 'C', 'GENDER'] = 'U'\n",
    "# categoricals.loc[categoricals['GENDER'] == 'A', 'GENDER'] = 'U'\n",
    "# categoricals.GENDER.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad242ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_combos = cartesian([ cat.columns[1:], cat.columns[1:]])\n",
    "# print(col_combos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c84bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = len(col_combos)\n",
    "ind_to_delete = []\n",
    "\n",
    "for i in range(0, len(col_combos)-1):\n",
    "    if col_combos[i][0] == col_combos[i][1]:\n",
    "        ind_to_delete.append(i) \n",
    "\n",
    "col_combos = np.delete(col_combos, ind_to_delete, axis=0)\n",
    "print(len(ind_to_delete))\n",
    "print(ind_to_delete)\n",
    "print(col_combos)\n",
    "\n",
    "#print(len(col_combos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6164d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_table_ind=pd.crosstab(cat[\"RFA_2\"],cat[\"RFA_3\"])\n",
    "print('contingency_table :\\n',ct_table_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f9f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_stat, p, dof, expected = stats.chi2_contingency(ct_table_ind)\n",
    "print(f\"chi2 statistic:     {chi2_stat:.5g}\")\n",
    "print(f\"p-value:            {p:.5g}\")\n",
    "print(f\"degrees of freedom: {dof}\")\n",
    "print(\"expected frequencies:\\n\",expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37d8907",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = 0.95\n",
    "critical = chi2.ppf(prob, dof)\n",
    "if abs(chi2_stat) >= critical:\n",
    "\tprint('Dependent (reject H0)')\n",
    "else:\n",
    "\tprint('Independent (fail to reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6fc073",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = pd.DataFrame(n_dependancies_ph.Hypothesis.value_counts())\n",
    "tt.reset_index()\n",
    "tt[['Reject Null Hypothesis', 'Fail to Reject Null Hypothesis']] = pd.DataFrame([[tt['Hypothesis'][0], tt['Hypothesis'][1]]], index=tt.index)\n",
    "tt = tt.rename(columns={'Hypothesis': 'column_name'})\n",
    "tt['column_name'] = 'RFA_2A'\n",
    "tt.reset_index()\n",
    "tt = tt.iloc[1:, :]\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777604d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_chi2(df, col):\n",
    "    check = {}\n",
    "    for i in n_dependancies.column_name:\n",
    "        dummies = pd.get_dummies(df[i])\n",
    "        adjusted_p_value = 0.05/df[i].nunique()  # using the Bonferroni-adjusted method for correcting the p-value, adjusting it by the number of pairwise comparisons we will do\n",
    "        for series in dummies:\n",
    "            if stats.chi2_contingency(pd.crosstab(df[col], dummies[series]))[1] < adjusted_p_value:\n",
    "                check['{}-{}'.format(i, series)] = 'Reject Null Hypothesis'\n",
    "            else:\n",
    "                check['{}-{}'.format(i, series)] = 'Fail to Reject Null Hypothesis'\n",
    "    n_dependancies_ph = pd.DataFrame(data = [check.keys(), check.values()]).T\n",
    "    n_dependancies_ph.columns = ['Pair', 'Hypothesis']\n",
    "    n_dependancies_ph\n",
    "    return n_dependancies_ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4fdc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_reject = []\n",
    "more_fail = []\n",
    "\n",
    "for col in n_dependancies:\n",
    "    count_hyp = check_chi2(cat_light, n_dependancies, col)\n",
    "    reject = n_dependancies_ph.Hypothesis.value_counts()[0]\n",
    "    fail = n_dependancies_ph.Hypothesis.value_counts()[1]\n",
    "    if reject > fail:\n",
    "        more_reject.append(col)\n",
    "    else:\n",
    "        more_fail.append(col)\n",
    "\n",
    "print(more_reject)\n",
    "print(more_fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec306404",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_reject = []\n",
    "more_fail = []\n",
    "\n",
    "for col in n_dependancies.column_name:\n",
    "    check = {}\n",
    "    for i in n_dependancies.column_name:\n",
    "        if i != col:\n",
    "            print(i)\n",
    "            dummies = pd.get_dummies(cat_light[i])\n",
    "            adjusted_p_value = 0.05/cat_light[i].nunique()  # using the Bonferroni-adjusted method for correcting the p-value, adjusting it by the number of pairwise comparisons we will do\n",
    "            for series in dummies:\n",
    "                print(series)\n",
    "                if stats.chi2_contingency(pd.crosstab(cat_light[col], dummies[series]))[1] < adjusted_p_value:\n",
    "                    check['{}-{}'.format(i, series)] = 'Reject Null Hypothesis'\n",
    "                else:\n",
    "                    check['{}-{}'.format(i, series)] = 'Fail to Reject Null Hypothesis'\n",
    "        n_dependancies_ph = pd.DataFrame(data = [check.keys(), check.values()]).T\n",
    "        n_dependancies_ph.columns = ['Pair', 'Hypothesis']\n",
    "        print(n_dependancies_ph)\n",
    "        print(n_dependancies_ph.Hypothesis.value_counts()[0])\n",
    "        #reject = n_dependancies_ph.Hypothesis.value_counts()[0]\n",
    "        #fail = n_dependancies_ph.Hypothesis.value_counts()[1]\n",
    "        #if reject > fail:\n",
    "            #more_reject.append(col)\n",
    "        #else:\n",
    "            #more_fail.append(col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13efaebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputer.fit(discrete_df)\n",
    "# dis_imputed = imputer.transform(discrete_df)\n",
    "# dis_imputed = pd.DataFrame(dis_imputed, columns=discrete_df.columns)\n",
    "# dis_imputed.isna().sum()\n",
    "\n",
    "# takes waaaaayyyy too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cb43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use the Log Transformation to reduce the skewness of the numerical variables\n",
    "def log_transfom_x(x):\n",
    "    if np.isfinite(x) and x!=0:\n",
    "        return np.log(x)\n",
    "    else:\n",
    "        return np.NAN\n",
    "\n",
    "def log_transform_df(df):\n",
    "    for col in df.columns:\n",
    "        df[col] = list(map(log_transfom_x, df[col]))\n",
    "        # replacing the nans with the mean of the new distribution\n",
    "        df[col] = df[col].fillna(np.mean(df[col]))\n",
    "        df[col] = np.log(df[col])\n",
    "        #create histograms\n",
    "    axs[0].hist(con_df, edgecolor='black')\n",
    "    axs[1].hist(con_df_log, edgecolor='black')\n",
    "    #add title to each histogram\n",
    "    axs[0].set_title('Original Data')\n",
    "    axs[1].set_title('Log-Transformed Data')\n",
    "        #sns.distplot(df[col], fit=norm)\n",
    "        #fig = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b471d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "con_df_log = con_df.copy()\n",
    "for col in con_df_log.columns:\n",
    "    con_df_log[col] = list(map(log_transfom_x, con_df_log[col]))\n",
    "    \n",
    "for col in con_df_log.columns:\n",
    "    con_df_log[col] = con_df_log[col].fillna(np.mean(con_df_log[col]))\n",
    "con_df_log\n",
    "\n",
    "for col in con_df_log:\n",
    "    sns.distplot(con_df_log[col])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9762672",
   "metadata": {},
   "outputs": [],
   "source": [
    "notinf = np.isfinite(con_df_log)\n",
    "  \n",
    "for col in notinf:\n",
    "    for i in col:\n",
    "        if i == 'False':\n",
    "            print(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43776dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in con_df_log.columns:\n",
    "    if con_df_log[col].isna().sum() > 0:\n",
    "        print(col, ': ', con_df_log[col].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13d59e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_drop_p(df, metric, threshold):\n",
    "    ols_to_keep = []\n",
    "    df['column_name'] = df.index\n",
    "    df = df[(df[metric] <= 0.05)]\n",
    "    for x in df['column_name'].unique():\n",
    "        if x != 'const':\n",
    "            ols_to_keep.append(x)\n",
    "    print(ols_to_keep)\n",
    "    return ols_to_keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_drop_high_p(ols_df, df, metric, threshold):\n",
    "    ols_to_keep = []\n",
    "    ols_df['column_name'] = ols_df.index\n",
    "    ols_df = ols_df[(ols_df[metric] <= 0.05)]\n",
    "    for x in ols_df['column_name'].unique():\n",
    "        if x != 'const':\n",
    "            ols_to_keep.append(x)\n",
    "    print(ols_to_keep)\n",
    "    df = df[ols_to_keep]\n",
    "    return df   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
